defmodule OlxScraper do
  use Crawly.Spider
  use Crawly
  alias Crawly.Utils

  @impl Crawly.Spider
  def base_url(), do: "https://www.olx.pl"

  @impl Crawly.Spider
  def init(), do: [start_urls: ["https://www.olx.pl/nieruchomosci/mieszkania/wynajem/"]]

  @impl Crawly.Spider
  def parse_item(res) do
    # First page only 
    {:ok, document} = Floki.parse_document(res.body)

    flat_urls =
      document
      |> Floki.find("tr td div table tbody tr td a.link")
      |> Floki.attribute("href")
      |> Enum.reject(&(!String.contains?(&1, base_url())))
      |> Enum.uniq()
      |> Enum.map(&Crawly.Utils.request_from_url/1)
      |> get_price()

    IO.inspect(flat_urls)
  end

  @impl Crawly.Spider
  defp get_price(url) do
    fetch(url)
  end
end
